\section{Conclusion}
The recent development of large generative models has shifted the online information ecosystem and necessitates a corresponding shift in the way platforms govern online content to address the ways AI-generated content cause harms to online trust and safety. While existing governance efforts and much of the current research rightly focus on mitigating explicit harms of AI-generated content, such as abusive deepfakes and harmful generation from AI, we argued that this focus is no longer sufficient. Emerging challenges to trust and safety from the recent surge of AI-generated content, such as debates around content ownership and monetization, still need to be addressed by extending the current governance framework. We propose suggestions for online platforms, AI service providers, regulators, and researchers on moving toward more proactive, ecosystem-oriented governance. As generative AI continues to evolve, treating AI-generated content as part of the infrastructure of online information systems rather than solely as a series of isolated incidents will support online trust and safety more broadly.