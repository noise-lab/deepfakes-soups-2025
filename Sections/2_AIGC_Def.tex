\section{AI-Generated Content and Its Governance: Definition}
\label{sec:def}
We first clarify our definition of AI-generated content (Section \ref{subsec:AIGC}) and the governance of AI-generated content (Section \ref{subsec:govAIGC}) in this paper, given the lack of a shared consensus on these concepts across existing research and practice.

\subsection{AI-Generated Content}
\label{subsec:AIGC}
\textit{AI-generated content} is a concept originally extended from earlier notions of \textit{computer-generated content} and \textit{machine-generated content}, which broadly refer to media produced by computer systems. While generative networks---the earliest form of generative AI models---were developed in the early 2010s, the term AI-generated content was not widely used until 2022-2023 when commercial generative AI products surged. Since then, it has been used by both stakeholders and the general public, mainly to emphasize the generation capability of large generative models across modalities such as text, images, audio, and video \cite{cao2025survey, foo2025ai}. 

The term AI-generated content has an evolving scope with ambiguous boundaries across different contexts. Typically, AI-generated content indicates content that is fully generated by generative AI models, as opposed to content made by humans~\cite{cao2025survey}. Yet, with the increasing use of generative AI in content creation and daily communication, whether content is AI-generated or not is no longer a binary yes or no, but a spectrum of when, where, and how AI participates in the content production. Therefore, terms like \textit{AI-assisted content} and \textit{human-AI co-creation} have been created to describe the nuances of how AI is partially engaged in the content with its generation capability (e.g.,~\cite{lloyd2025ai, 10.1145/3715336.3735683}). However, the term AI-generated content is still widely used to cover a range of this AI participation spectrum in content creation. For example, when mentioning AI-generated content in their policies, online platforms usually refer to content that is fully generated, significantly altered, or with major components generated by AI~\cite{gao2026governance}.

In this paper, we therefore adopt a broad working definition of AI-generated content to encompass content that is fully generated by generative AI models, as well as content that is produced through AI participation, such as AI-altered, AI-assisted, or human-AI collaborative processes. We also consider deepfakes and synthetic media as AI-generated content as long as their production involves generative AI.


\subsection{Governance of AI-Generated Content}
\label{subsec:govAIGC}
In this paper, we conceptualize the \textit{governance of AI-generated content} by drawing on two distinct bodies of work on technology governance: \textit{AI governance} and \textit{platform governance}. AI governance broadly focuses on the whole life cycle of development, deployment, and oversight of AI systems, emphasizing the breadth of concerns such as safety, accountability, transparency, fairness, and compliance through technical solutions, policymaking, and regulations~\cite{taeihagh2021governance, butcher2019state}. Platform governance, meanwhile, indicates policies, technical mechanisms, and design decisions that affect user interactions in digital platforms such as social media and online marketplaces, addressing a wide range of concerns like online safety, digital privacy, monetization, and free speech~\cite{gorwa2019platform}. According to prior works, platform governance usually refers to the governance \textit{by} platforms---how online platforms govern their ecosystem that bridges user expectations and regulatory requirements. In contrast, the governance \textit{of} platforms incorporates inputs from different parties that shape governance by platforms~\cite{gorwa2019platform, gillespie2017governance}. Compared to AI governance, where both the governance objects and actors are often problem-specific, digital platforms function as the center of platform governance, where their governance decisions are enacted and encountered directly by their end-users. 

We situate the governance of AI-generated content in online spaces within the intersection of AI governance and platform governance. On the one hand, the concerns of AI-generated content have become a focus in generative AI governance, covering topics like the governance of deepfake~\cite{geng2023comparing}, harmful output from generative AI~\cite{gao2025cannot,hacker2023regulating}, and consent and credit of creative works used as training data~\cite{kyi2025governance}. On the other hand, within platform governance, AI-generated content produced and distributed by users has been treated as a subtype of user-generated content hosted by the platform. The prevalence of AI-generated content has led to the development of external regulations and platform policies that target such content exclusively~\cite{gao2026governance}, indicating that AI-generated content has become a rising focus in platform governance. 

Under this context, we define the governance of AI-generated content as the collection of regulations, policies, principles, technical mechanisms, and design solutions developed by different stakeholders---such as online platforms, AI service providers, regulators, and researchers---to address the challenges introduced by AI-generated content. While these governance efforts are shaped by diverse stakeholders across the AI supply chain, they are ultimately reflected through governance by platforms. That is, online platforms serve as downstream sites in AI-generated content governance, directly influencing end-users by developing policies, mechanisms, and designs that shape and manage the production, presentation, and distribution of AI-generated content within their ecosystems.