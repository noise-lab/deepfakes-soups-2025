\section{AI-Generated Content and Its Governance: Definition}
\label{sec:def}
Before we deepen the discussion on the governance of AI-generated content in online spaces, we first clarify our definition of AI-generated content (Section \ref{subsec:AIGC}) and the governance of AI-generated content (Section \ref{subsec:govAIGC}) in this paper, given the lack of a shared consensus on these concepts across existing research and practice.

\subsection{AI-Generated Content}
\label{subsec:AIGC}
\textit{AI-generated content} is a concept originally extended from earlier notions of \textit{computer-generated content} and \textit{machine-generated content}, which broadly refer to media produced by computer systems~\cite{}. While generative networks---the earliest form of generative AI models---have been developed in the early 2010s, the term AI-generated content was not remarked upon until 2022-2023 when consumer-facing generative AI products surged. Since then, it has been widely used by industry practitioners, researchers, regulators, and the general public, mainly to emphasize the generation capability of large generative models across modalities such as text, images, audio, and video (e.g., \cite{}). 

Until now, the term AI-generated content has an evolving scope with its boundaries remaining conceptually and operationally ambiguous across different contexts. Typically, AI-generated content indicates content that is fully generated by generative AI models, as opposed to content made by humans. In contexts like online communities, however, AI-generated content is also used in comparison to user-generated content and platform-generated content by researchers and platforms~\cite{}. With the increasing use of generative AI in content creation and daily communication, whether content is AI-generated is no longer a binary yes or no, but a spectrum of when, where, and how AI participates in the content production process. Therefore, people have developed terms like \textit{AI-assisted content} and \textit{human-AI co-creation} to describe the nuances of how AI is partially engaged in the content with its generation capability~\cite{}. While AI-generated content, as one of the most well-known concepts by the general public, is widely used to cover a range of this AI participation spectrum in content creation without a fixed boundary. For example, when mentioning AI-generated content in their policy, online platforms could refer to content that is fully generated, significantly altered, or with its major components generated by AI~\cite{}.

In this paper, we therefore adopt a deliberately broad working definition of AI-generated content to encompass content that is fully generated by generative AI models, as well as content that is produced through AI participation, such as AI-altered, AI-assisted, or human-AI collaborative processes. We also consider deepfakes and synthetic media, as long as their production involves generative AI, within our definition of AI-generated content. This inclusive definition allows us to reflect real-world governance practices of generative AI in content production, where distinctions among different types of AI engagement are sometimes not clearly underlined, and to examine the governance implications of AI-generated content more holistically.


\subsection{Governance of AI-Generated Content}
\label{subsec:govAIGC}
In this paper, we conceptualize the \textit{governance of AI-generated content} by drawing on two distinct bodies of work on technology governance: \textit{AI governance} and \textit{platform governance}. AI governance broadly focuses on the whole life cycle of development, deployment, and oversight of AI systems, emphasizing the breadth of concerns such as safety, accountability, transparency, fairness, and compliance through technical solutions, policymaking, and regulations~\cite{}. The governance of AI involves various stakeholders and domains at multiple levels, from AI practitioners to regulators and researchers, resulting in relatively unorganized practices and fragmented pipelines~\cite{}. Platform governance, by contrast, indicates policies, technical mechanisms, and design decisions that affect user interactions in digital platforms such as social media and online marketplaces, also addressing a wide range of concerns like online safety, digital privacy, monetization, and free speech~\cite{}. As of prior works, platform governance usually refers to the governance \textit{by} platforms---how platforms govern their ecosystem that bridges user expectations and regulatory requirements. While the governance \textit{of} platforms usually incorporates inputs from different parties, including platform companies, users, regulators, advertisers, and so on~\cite{}. Compared to AI governance, where both the governance objects and actors are often problem-specific, digital platforms function as the center of platform governance, where their governance decisions are enacted and encountered directly by the platform's end-users.

We situate the governance of AI-generated content in online spaces within the intersection of AI governance and platform governance. On the one hand, the concerns and risks AI-generated content has been considered as a part of focus in generative AI governance, with emerging highlights on topics like the governance of deepfake production and distribution~\cite{}, harmful output from generative AI systems and services~\cite{}, and consent and credit by creative workers~\cite{}. On the other hand, within platform governance, AI-generated content produced and distributed by users has been treated as a subtype of user-generated content hosted by the platform. While risks around general user-generated content have been addressed through existing, well-developed platform governance practices like content moderation, the increasing prevalence of AI-generated content leads to the development of external regulations and platform policies that target such content exclusively~\cite{}, indicating that AI-generated content has become a rising focus in platform governance. 

Under this context, we define the governance of AI-generated content as the collection of regulations, policies, principles, technical mechanisms, and design solutions developed by different stakeholders---such as AI practitioners, online platforms, regulators, and researchers---to address the challenges introduced by AI-generated content. While these governance efforts are shaped by diverse stakeholders across the AI supply chain, they are ultimately reflected through governance by online platforms. That is, platforms serve as the downstream sites in AI-generated content governance that directly influence end-users, developing policies, mechanisms, and designs that shape and manage the production, presentation, and distribution of AI-generated content within their ecosystem.