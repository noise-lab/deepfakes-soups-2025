\section{Call For Action}
\label{sec:cfa}
Through a review of the current governance framework on AI-generated content (Section \ref{sec:history}) and discussion on why such a framework should be extended (Section \ref{sec:discuss}), we claim that if generative AI and AI-generated content are becoming part of the foundational infrastructure of the online information ecosystem, then governance cannot stop at mitigating explicit harm. 

Building on our position and discussion, we outline an agenda for online platforms, AI developers and providers, regulators, and researchers to address challenges on how the surge of AI-generated content reshapes user experience, creator rights, and community value that ultimately influence online trust and safety. Rather than replacing existing measures, our recommendations aim to extend them towards a more proactive, ecosystem-oriented governance of AI-generated content.

\subsection{Recommendations for Online Platforms}
\paragraph{Incentivize creators to responsibly use generative AI in content creation.} To address those new challenges, we suggest that online platforms turn their stance from restriction of ``bad'' content to encouragement of responsible practices. For example, for the challenges rise from low-quality AI-generated content, Completely banning creators keep produce AI slop or downgrading low-quality content could infeasible in cost given the high volume of AI-generated content, unclear boundary of low-quality content, and the ithe platform should encourage users to create high-quality content with more human effort and intellectual contribution to creativity. Similarly, encourage users to disclose AI-generated content regarding content authenticity and ownership. Since labeling AI-generated content has negative effect on user perception and even algorithm rating, for which platplatforms should give particular incentives to users who keep responsible use of genAI by upgrading promotion, more rewards, etc. 

Under the new trend of generative AI use in content creation, it is also important to educate creator about. A recent study on short video creators reveals their urgent needs for platforms to provide tools and guidelines on using AI to create `ethical and responsibleâ€™ content, particularly to avoid unintentional copyright violation and to clarify their responsibilities toward audiences as creators~\cite{kim2024unlocking}. However, studies reveal that to date, only a few platforms have offered concrete guidelines on how generative AI should be responsibly used in content creation, or how to make high-quality AI-generated content, beyond the guidance on AI-generated content disclosure~\cite{gao2026governance}.

\paragraph{Empowering users through educational materials and controls} Since AI-generated content keep dominant the online information ecosystem, it has become more than urgent to equip users with more awareness and autonomy around the flood of AI-generated content to countermeasure the invisible damages on user cognition (Section \ref{subsubsec:invisibledamage}). However, as we reviewed in Section \ref{subsubsec:deepfakegovresponse} and Section \ref{subsubsec:AIGCgovresponse}, prior research developing user empowerment centers on identifying high-stakes deepfake manipulation. Such user support is also limited in the wild. Prior work reveals that in online platforms, labeling systems are usually the only tool for users to navigate AI-generated content, while other educational materials and user control on AI-generated content are rare-find~\cite{gao2026governance}. While AI-generated content labels, as we already discussed in Section \ref{subsubsec:labelingtradeoff}, could otherwise compromise user trust in mislabel cases.

Therefore, we suggest First, platforms could incorporate AI-generated content into their media literacy materials

\subsection{Recommendations for AI Developers and Service Providers}
\paragraph{Extend Safety Guardrail and Watermark-based Provenance to Authorship}
Effort, such as prompt length on a fully AI-generated material, generation time, etc.

\subsection{Recommendations for Regulators}
\paragraph{Updating the current regulations in AI-generated content.} 
Copyright law: not only on binary who owns the content (copyright), but also to evaluate the composition of contribution among creators who generated AI-generated content, the AI model and company, and the training data provider. 

On the Transparency of AI-generated content: only China have such rule on labeling everything. Also, platforms claim they label AIGC as long as they detect it. Regulators could develop official rules on what to disclose and what not to disclose in online distribution

\paragraph{Building guidelines for best practice on AIGC governance}
Current governmental guidelines usually cover general AI harms and deepfake manipulation. As the governance of AI-generated content online needs to be updated, there is an urgent need of official guidance, including case examples on emerging harms, what harms are high-stakes and what are low-stakes, governance framework on minimum governance efforts for both online platforms and AI service providers. Such guidance could especially focus on emerging concerns like AI slop and suggestions on how to maintain community value through govern AI-generated content. Also need official guidance on responsible production and distribution of AI-generated content, which to date is limited~\cite{}.

\subsection{Recommendations for Researchers}
1. Study more on new challenges and their effect on online trust and safety in the real world? like ownership, failures of labels, AI slop how users, especially the vulnerable population, react to new challenges?

measurement on what is happening around trust and safety (consequences)
in-situ

2. Develop countermeasure on new challenges and test their effectiveness?
such as contested ownership