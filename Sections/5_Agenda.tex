\section{Call For Action}
\label{sec:cfa}
Through a review of the current governance framework on AI-generated content (Section \ref{sec:history}) and discussion on why such a framework should be extended (Section \ref{sec:discuss}), we claim that if generative AI and AI-generated content are becoming part of the foundational infrastructure of the online information ecosystem, then governance cannot stop at mitigating explicit harm. Below, we outline an agenda for online platforms, AI developers and providers, regulators, and researchers to address challenges on how the surge of AI-generated content reshapes user experience, creator rights, and community value that compromise online t. Rather than replacing existing measures, our recommendations aim to extend them towards a more proactive, ecosystem-oriented governance of AI-generated content.

\subsection{Recommendations for Online Platforms}
From restriction and enforcement to encouragement and empowerment

1.  Incentivize creators to make high-quality AI-generated content and share responsibly: For the problem of low-quality content,  instead of completely banning low-quality content, which is also infeasible given the high volume, the platform should encourage users to create high-quality content with more human efforts and intellectual contribution to creativity.

Similarly, encourage users to disclose AI-generated content regarding content authenticity and ownership. Since labeling AI-generated content has bad effect on user perception and even algorithm rating, platforms should give particular incentives to users who keep responsible use of genAI by upgrading promotion, more rewards, etc.

Provide guidelines and tools for creators on responsible use of AI: [Move content of section 4.4 here?] 

2. Empowering users through educational materials and controls: As reviewed in Section 3, till now, prior works on user empowerment center on identifying deepfake manipulation. In online platforms, labeling system are the only 

\subsection{Recommendations for AI Developers and Service Providers}
1. Extend Safety Guardrail and Watermark-based Provenance to Authorship
Effort, such as prompt length on a fully AI-generated material, generation time, etc.

\subsection{Recommendations for Regulators}
1. Updating the current regulations in AI-generated content: 
Copyright law: not only on binary who owns the content (copyright), but also to evaluate the composition of contribution among creators who generated AI-generated content, the AI model and company, and the training data provider. 

On the Transparency of AI-generated content: only China have such rule on labeling everything. Also, platforms claim they label AIGC as long as they detect it. Regulators could develop official rules on what to disclose and what not to disclose in online distribution

2. Building guidelines for best practice on AIGC governance
Current governmental guidelines usually cover general AI harms and deepfake manipulation. As the governance of AI-generated content online needs to be updated, there is an urgent need of official guidance, including case examples on emerging harms, what harms are high-stakes and what are low-stakes, governance framework on minimum governance efforts for both online platforms and AI service providers. Such guidance could especially focus on emerging concerns like AI slop and suggestions on how to maintain community value through govern AI-generated content. Also need official guidance on responsible production and distribution of AI-generated content, which to date is limited~\cite{}.

\subsection{Recommendations for Researchers}
1. Study more on new challenges and their effect on online trust and safety in the real world? like ownership, failures of labels, AI slop how users, especially the vulnerable population, react to new challenges?

measurement on what is happening around trust and safety (consequences)
in-situ

2. Develop countermeasure on new challenges and test their effectiveness?
such as contested ownership